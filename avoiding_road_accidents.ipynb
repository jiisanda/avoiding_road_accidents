{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a77807f92f26ee",
   "metadata": {},
   "source": [
    "# Avoiding Road Accidents\n",
    "\n",
    "## Dataset: \n",
    "\n",
    "http://vllab1.ucmerced.edu/~hhsu22/rear_signal/rear_signal#\n",
    "\n",
    "### Dataset statistics\n",
    "\n",
    "Total sequences: 649\n",
    "Total frames: 63637\n",
    "\n",
    "*Number of sequences in each class*:\n",
    "\n",
    "OOO: 188 BOO: 211 OLO: 78 BLO: 63\n",
    "\n",
    "OOR:  58 BOR:  33 OLR:  9 BLR:  9\n",
    "\n",
    "*Number of frames in each class:*:\n",
    "\n",
    "\n",
    "OOO: 21867 BOO: 17874 OLO: 6271 BLO: 6380\n",
    "\n",
    "OOR:  4728 BOR:  3527 OLR: 1600 BLR: 1390"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbc121e30a2defb3",
   "metadata": {},
   "source": [
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.get_device_name(0)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef3f115278104098",
   "metadata": {},
   "source": [
    "!pip install opencv-python\n",
    "!pip install ultralytics"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a72c7422c9297302",
   "metadata": {},
   "source": [
    "import logging\n",
    "\n",
    "# Setup logger\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4a5cbd3c90718f1c",
   "metadata": {},
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3cf74c6cd46f9631",
   "metadata": {},
   "source": [
    "os.makedirs(\"data/yolo_dataset/images/train\", exist_ok=True)\n",
    "os.makedirs(\"data/yolo_dataset/images/val\", exist_ok=True)\n",
    "os.makedirs(\"data/yolo_dataset/labels/train\", exist_ok=True)\n",
    "os.makedirs(\"data/yolo_dataset/labels/val\", exist_ok=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "782aad68ff6d32ec",
   "metadata": {},
   "source": [
    "# Define class mapping\n",
    "class_mapping = {\n",
    "    'OOO': 0,  # Normal\n",
    "    'BOO': 1,  # Braking\n",
    "    'OLO': 2,  # Left signal\n",
    "    'BLO': 3,  # Brake + Left signal\n",
    "    'OOR': 4,  # Right signal\n",
    "    'BOR': 5,  # Brake + Right signal\n",
    "    'OLR': 6,  # Hazard lights\n",
    "    'BLR': 7   # Brake + Hazard lights\n",
    "}\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e76cbcef",
   "metadata": {},
   "source": [
    "def detect_taillights(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        return None, None\n",
    "        \n",
    "    # Get image dimensions for calculating relative values later\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # Define red color range for taillights\n",
    "    lower_red1 = np.array([0, 100, 100])\n",
    "    upper_red1 = np.array([10, 255, 255])\n",
    "    lower_red2 = np.array([160, 100, 100])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    \n",
    "    # Create masks for red regions\n",
    "    mask1 = cv2.inRange(hsv, lower_red1, upper_red1)\n",
    "    mask2 = cv2.inRange(hsv, lower_red2, upper_red2)\n",
    "    mask = cv2.bitwise_or(mask1, mask2)\n",
    "    \n",
    "    # Apply morphological operations\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Filter contours based on area\n",
    "    min_area = 50\n",
    "    valid_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_area]\n",
    "    \n",
    "    if valid_contours:\n",
    "        all_x = []\n",
    "        all_y = []\n",
    "        for contour in valid_contours:\n",
    "            for point in contour:\n",
    "                all_x.append(point[0][0])\n",
    "                all_y.append(point[0][1])\n",
    "        \n",
    "        # Calculate absolute coordinates with padding\n",
    "        x_min = max(min(all_x) - 10, 0)\n",
    "        x_max = min(max(all_x) + 10, width)\n",
    "        y_min = max(min(all_y) - 5, 0)\n",
    "        y_max = min(max(all_y) + 5, height)\n",
    "        \n",
    "        # Convert to YOLO format (x_center, y_center, width, height) - all relative\n",
    "        x_center = (x_min + x_max) / (2 * width)  # relative center x\n",
    "        y_center = (y_min + y_max) / (2 * height)  # relative center y\n",
    "        rel_width = (x_max - x_min) / width  # relative width\n",
    "        rel_height = (y_max - y_min) / height  # relative height\n",
    "        \n",
    "        return True, (x_center, y_center, rel_width, rel_height)\n",
    "    \n",
    "    return False, None"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "94acf1944bb870d4",
   "metadata": {},
   "source": [
    "def process_images(footage_path, split='train'):\n",
    "    footage_path = Path(footage_path)\n",
    "    frame_paths = list(footage_path.rglob('light_mask/frame*.png'))\n",
    "    logger.info(f\"Found {len(frame_paths)} frames\")\n",
    "\n",
    "    # Create directories if they don't exist\n",
    "    Path(f\"data/yolo_dataset/images/{split}\").mkdir(parents=True, exist_ok=True)\n",
    "    Path(f\"data/yolo_dataset/labels/{split}\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for frame_path in frame_paths:\n",
    "        try:\n",
    "            # Debug print the full frame path\n",
    "            # logger.info(f\"Processing frame: {frame_path}\")\n",
    "            # logger.info(f\"Frame path exists: {frame_path.exists()}\")\n",
    "\n",
    "            # Extract class from path\n",
    "            frame_path_str = str(frame_path)\n",
    "            for class_name in class_mapping.keys():\n",
    "                if f\"_{class_name}_\" in frame_path_str:\n",
    "                    break\n",
    "            else:\n",
    "                logger.error(f\"Could not find class name in path: {frame_path}\")\n",
    "                continue\n",
    "\n",
    "            # Generate filenames\n",
    "            filename = frame_path.name\n",
    "            dest_path = Path(f\"data/yolo_dataset/images/{split}/{filename}\")\n",
    "            label_path = Path(f\"data/yolo_dataset/labels/{split}/{filename}\").with_suffix('.txt')\n",
    "\n",
    "            # Debug print the destination path\n",
    "            # logger.info(f\"Destination path: {dest_path}\")\n",
    "\n",
    "            # Verify source file exists before copying\n",
    "            if not frame_path.exists():\n",
    "                logger.error(f\"Source file does not exist: {frame_path}\")\n",
    "                continue\n",
    "\n",
    "            # Create parent directories if they don't exist\n",
    "            dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            # Copy image\n",
    "            try:\n",
    "                shutil.copy2(str(frame_path), str(dest_path))\n",
    "            except Exception as copy_error:\n",
    "                logger.error(f\"Error copying file: {str(copy_error)}\")\n",
    "                logger.error(f\"From: {frame_path}\")\n",
    "                logger.error(f\"To: {dest_path}\")\n",
    "                continue\n",
    "\n",
    "            # Detect taillights and get YOLO format coordinates\n",
    "            success, bbox = detect_taillights(frame_path)\n",
    "\n",
    "            # Create label file with detected coordinates or fallback values\n",
    "            with open(label_path, 'w') as f:\n",
    "                if success and bbox:\n",
    "                    x_center, y_center, rel_width, rel_height = bbox\n",
    "                    f.write(f'{class_mapping[class_name]} {x_center:.6f} {y_center:.6f} {rel_width:.6f} {rel_height:.6f}\\n')\n",
    "                else:\n",
    "                    # Fallback to default values if detection fails\n",
    "                    logger.warning(f\"Detection failed for {filename}, using default values\")\n",
    "                    f.write(f'{class_mapping[class_name]} 0.5 0.8 0.3 0.2\\n')\n",
    "\n",
    "            # logger.info(f\"Successfully processed: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {frame_path}: {str(e)}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8221f176c6c2aa14",
   "metadata": {},
   "source": [
    "base_path = Path(\"data/rear_signal_dataset\")\n",
    "\n",
    "with open('data/rear_signal_dataset/Easy.txt', 'r') as f:\n",
    "    easy_sequences = f.read().splitlines()\n",
    "logger.info(f\"Found {len(easy_sequences)} easy sequences\")\n",
    "\n",
    "# Split into train and validation\n",
    "train_sequences = easy_sequences[:int(len(easy_sequences)*0.8)]\n",
    "val_sequences = easy_sequences[int(len(easy_sequences)*0.8):]\n",
    "\n",
    "logger.debug(f\"Processing {len(train_sequences)} train sequences...\")\n",
    "for seq in train_sequences:\n",
    "    # Reconstruct the correct path\n",
    "    # Extract the base parts of the sequence name\n",
    "    base_parts = seq.split('_')[:4]  # Get the first 4 parts\n",
    "    base_name = '_'.join(base_parts)\n",
    "    class_name = seq.split('_')[-2]  # Get class name (BOO, OOO, etc)\n",
    "    sequence_num = seq.split('_')[-1]  # Get sequence number\n",
    "\n",
    "    # Construct the full path\n",
    "    seq_path = base_path.joinpath(base_name, f\"{base_name}_{class_name}\", f\"{base_name}_{class_name}_{sequence_num}\")\n",
    "    # logger.debug(f\"Looking for sequence at: {seq_path}\")\n",
    "\n",
    "    if os.path.exists(seq_path):\n",
    "        process_images(seq_path, 'train')\n",
    "    else:\n",
    "        if base_parts[0].startswith('test'):\n",
    "            complete_split = seq.split('_')\n",
    "            if complete_split[2].startswith('idx'):\n",
    "                base_parts = seq.split('_')[:3]\n",
    "            else:\n",
    "                base_parts = seq.split('_')[:2]\n",
    "            base_name = '_'.join(base_parts)\n",
    "            class_name = seq.split('_')[-2]\n",
    "            sequence_num = seq.split('_')[-1]\n",
    "\n",
    "            # construct full path for test\n",
    "            seq_path = base_path.joinpath(base_name, f\"{base_name}_{class_name}\", f\"{base_name}_{class_name}_{sequence_num}\")\n",
    "            # logger.debug(f\"Looking for sequence at: {seq_path}\")\n",
    "\n",
    "            if os.path.exists(seq_path):\n",
    "                process_images(seq_path, 'train')\n",
    "            else:\n",
    "                logger.error(f\"Sequence path does not exist: {seq_path}\")\n",
    "\n",
    "\n",
    "logger.debug(f\"Processing {len(val_sequences)} validation sequences...\")\n",
    "for seq in val_sequences:\n",
    "    # logger.debug(f\"Processing validation sequence: {seq}\")\n",
    "    base_parts = seq.split('_')[:4]\n",
    "    base_name = '_'.join(base_parts)\n",
    "    class_name = seq.split('_')[-2]\n",
    "    sequence_num = seq.split('_')[-1]\n",
    "\n",
    "    seq_path = base_path.joinpath(base_name, f\"{base_name}_{class_name}\", f\"{base_name}_{class_name}_{sequence_num}\")\n",
    "\n",
    "    if os.path.exists(seq_path):\n",
    "        process_images(seq_path, 'val')\n",
    "    else:\n",
    "        if base_parts[0].startswith('test'):\n",
    "            complete_split = seq.split('_')\n",
    "            if complete_split[2].startswith('idx'):\n",
    "                base_parts = seq.split('_')[:3]\n",
    "            else:\n",
    "                base_parts = seq.split('_')[:2]\n",
    "            base_name = '_'.join(base_parts)\n",
    "            class_name = seq.split('_')[-2]\n",
    "            sequence_num = seq.split('_')[-1]\n",
    "\n",
    "            # Construct full path for test\n",
    "            seq_path = base_path.joinpath(base_name, f\"{base_name}_{class_name}\", f\"{base_name}_{class_name}_{sequence_num}\")\n",
    "            # logger.debug(f\"Looking for sequence at: {seq_path}\")\n",
    "\n",
    "            if os.path.exists(seq_path):\n",
    "                process_images(seq_path, 'val')\n",
    "            else:\n",
    "                logger.error(f\"Sequence path does not exist: {seq_path}\")\n",
    "\n",
    "\n",
    "# Print final statistics\n",
    "train_images = len(glob('data/yolo_dataset/images/train/*.png'))\n",
    "val_images = len(glob('data/yolo_dataset/images/val/*.png'))\n",
    "\n",
    "logger.info(f\"Final Statistics:\")\n",
    "logger.info(f\"Training images: {train_images}\")\n",
    "logger.info(f\"Validation images: {val_images}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "still have 3406 out of 15432 frames having default boundary box values",
   "id": "4760c1255c931a8f"
  },
  {
   "cell_type": "code",
   "id": "4a2384102c81a31e",
   "metadata": {},
   "source": [
    "# Create yaml file first\n",
    "yaml_content = f\"\"\"\n",
    "path: {os.path.abspath('data/yolo_dataset')}  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path')\n",
    "val: images/val  # val images (relative to 'path')\n",
    "\n",
    "# Classes\n",
    "nc: {len(class_mapping)}  # number of classes\n",
    "names: {list(class_mapping.keys())}  # class names\n",
    "\"\"\"\n",
    "\n",
    "with open('dataset.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f99c1d0ac6d491",
   "metadata": {},
   "source": [
    "!pip uninstall -y ultralytics\n",
    "!pip install torch torchvision ultralytics==8.0.196\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7e30eb93b379aaa7",
   "metadata": {},
   "source": "!yolo task=detect mode=train model=yolov8n.pt data=dataset.yaml epochs=5 imgsz=640 batch=16 device=cuda",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21c0e8cd3039b668"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
